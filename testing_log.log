Using username "pmahend1".
pmahend1@dsba-hadoop.uncc.edu's password:
Last login: Sun Nov  6 12:38:54 2016 from cpe-172-73-76-197.carolina.res.rr.com

                     University Research Computing
                  Information and Technology Services
               University of North Carolina at Charlotte

  NOTICE
  "Use of the University's computing and electronic communication
  resources is conditioned on compliance with the University's
  Information Technology (IT) policies (Policy Statements 8, 10,
  20, 66, 67, and 102).  Pursuant to those policies, the University
  will take any steps necessary to safeguard the integrity of the
  University's computing and electronic resources and to minimize
  the risks to both those resources and the end users of those
  resources.  Such safeguarding includes monitoring data traffic
  to detect anomalous network activity, as well as accessing,
  retrieving, reading, and/or disclosing data communications when
  there is reasonable cause to suspect a violation of applicable
  University policy or criminal law, or when monitoring is
  otherwise required or permitted by law."


============================================================================
                     Red Hat Enterprise Linux 7.2
============================================================================

[pmahend1@mba-i2 ~]$ hadoop jar /users/pmahend1/Jars/RandomForest-0.0.1-SNAPSHOT                                                                                        .jar Cancer/attributes.txt Cancer/data.txt
Exception in thread "main" java.lang.ClassNotFoundException: Cancer.attributes.t                                                                                        xt
        at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
        at java.lang.Class.forName0(Native Method)
        at java.lang.Class.forName(Class.java:348)
        at org.apache.hadoop.util.RunJar.run(RunJar.java:214)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:136)
[pmahend1@mba-i2 ~]$ hadoop jar /users/pmahend1/Jars/RandomForest-0.0.1-SNAPSHOT.jar rfalgorithm.RandomForest Cancer/attributes.txt Cancer/data.txt
==========Random Forest Algorithm==========
Available Attributes: [A, B, C, D, E, F, G, H, I, J, K]
1. Enter the Stable Attribute(s):
A
Stable Attribute(s): [A]
Available Attribute(s): [B, C, D, E, F, G, H, I, J, K]
1. Enter the Decision Attribute:
D

Available Decision Attributes: [D1, D2, D3, D4, D5, D8, D10]
Enter the Decision From Attribute:
D3
Enter the Decision To Attribute:
D7
Stable Attribute(s): [A]
Decision Attribute: [D]
Decision From Attribute: D3
Decision To Attribute: D7
Flexible Attribute(s): [B, C, E, F, G, H, I, J, K]
Enter the minimum Support:
3
Enter the minimum Confidence %:
50
Exception in thread "main" java.lang.ArrayIndexOutOfBoundsException: 2
        at rfalgorithm.RandomForest.main(RandomForest.java:187)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.apache.hadoop.util.RunJar.run(RunJar.java:221)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:136)
[pmahend1@mba-i2 ~]$ hadoop jar /users/pmahend1/Jars/RandomForest-0.0.1-SNAPSHOT.jar rfalgorithm.RandomForest Cancer/attributes.txt Cancer/data.txt
==========Random Forest Algorithm==========
Available Attributes: [A, B, C, D, E, F, G, H, I, J, K]
1. Enter the Stable Attribute(s):
a
Invalid Stable attribute(s)
Stable Attribute(s): []
Available Attribute(s): [A, B, C, D, E, F, G, H, I, J, K]
1. Enter the Decision Attribute:
1
Invalid Decision attribute(s)

Available Decision Attributes: [A1000025, A1017023, A1017122, A1016277, A1036172, A1002945, A1018099, A1018561, A1035283, A1041801, A1015425, A1033078, A1043999, A1044572]
Enter the Decision From Attribute:
1
Enter the Decision To Attribute:
1
Stable Attribute(s): []
Decision Attribute: []
Decision From Attribute: 1
Decision To Attribute: 1
Flexible Attribute(s): [A, B, C, D, E, F, G, H, I, J, K]
Enter the minimum Support:
1
Enter the minimum Confidence %:
1
1Exception in thread "main" java.lang.ArrayIndexOutOfBoundsException: 2
        at rfalgorithm.RandomForest.main(RandomForest.java:187)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.apache.hadoop.util.RunJar.run(RunJar.java:221)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:136)

[pmahend1@mba-i2 ~]$ 1
-bash: 1: command not found
[pmahend1@mba-i2 ~]$ hadoop jar /users/pmahend1/Jars/RandomForest-0.0.1-SNAPSHOT.jar rfalgorithm.RandomForest Cancer/car.c45-names.attributes.txt Car/car.data
Exception in thread "main" java.io.FileNotFoundException: Cancer/car.c45-names.attributes.txt (No such file or directory)
        at java.io.FileInputStream.open0(Native Method)
        at java.io.FileInputStream.open(FileInputStream.java:195)
        at java.io.FileInputStream.<init>(FileInputStream.java:138)
        at java.io.FileReader.<init>(FileReader.java:72)
        at rfalgorithm.RandomForest.main(RandomForest.java:125)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.apache.hadoop.util.RunJar.run(RunJar.java:221)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:136)
[pmahend1@mba-i2 ~]$ hadoop fs -put /users/pmahend1/Car
[pmahend1@mba-i2 ~]$ hadoop fs -ls Car
Found 2 items
-rw-r--r--   3 pmahend1 pmahend1         50 2016-11-06 18:19 Car/car.c45-names.attributes.txt
-rw-r--r--   3 pmahend1 pmahend1      51867 2016-11-06 18:19 Car/car.data.txt
[pmahend1@mba-i2 ~]$ hadoop jar /users/pmahend1/Jars/RandomForest-0.0.1-SNAPSHOT.jar rfalgorithm.RandomForest Cancer/car.c45-names.attributes.txt Car/car.data
Exception in thread "main" java.io.FileNotFoundException: Cancer/car.c45-names.attributes.txt (No such file or directory)
        at java.io.FileInputStream.open0(Native Method)
        at java.io.FileInputStream.open(FileInputStream.java:195)
        at java.io.FileInputStream.<init>(FileInputStream.java:138)
        at java.io.FileReader.<init>(FileReader.java:72)
        at rfalgorithm.RandomForest.main(RandomForest.java:125)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.apache.hadoop.util.RunJar.run(RunJar.java:221)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:136)
[pmahend1@mba-i2 ~]$ hadoop jar /users/pmahend1/Jars/RandomForest-0.0.1-SNAPSHOT.jar rfalgorithm.RandomForest Car/car.c45-names.attributes.txt Car/car.data
Exception in thread "main" java.io.FileNotFoundException: Car/car.data (No such file or directory)
        at java.io.FileInputStream.open0(Native Method)
        at java.io.FileInputStream.open(FileInputStream.java:195)
        at java.io.FileInputStream.<init>(FileInputStream.java:138)
        at java.io.FileReader.<init>(FileReader.java:72)
        at rfalgorithm.RandomForest.main(RandomForest.java:136)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.apache.hadoop.util.RunJar.run(RunJar.java:221)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:136)
[pmahend1@mba-i2 ~]$ hadoop jar /users/pmahend1/Jars/RandomForest-0.0.1-SNAPSHOT.jar rfalgorithm.RandomForest Car/car.c45-names.attributes.txt Car/car.data.txt
==========Random Forest Algorithm==========
Available Attributes: [buying, maint, doors, persons, lug_boot, safety, label]
1. Enter the Stable Attribute(s):
safety
Stable Attribute(s): [safety]
Available Attribute(s): [buying, maint, doors, persons, lug_boot, label]
1. Enter the Decision Attribute:
buying

Available Decision Attributes: [buyinghigh, buyinglow, buyingvhigh, buyingmed]
Enter the Decision From Attribute:
buyinglow
Enter the Decision To Attribute:
buyinghigh
Stable Attribute(s): [safety]
Decision Attribute: [buying]
Decision From Attribute: buyinglow
Decision To Attribute: buyinghigh
Flexible Attribute(s): [maint, doors, persons, lug_boot, label]
Enter the minimum Support:
3
Enter the minimum Confidence %:
50
Exception in thread "main" java.lang.ArrayIndexOutOfBoundsException: 2
        at rfalgorithm.RandomForest.main(RandomForest.java:187)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.apache.hadoop.util.RunJar.run(RunJar.java:221)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:136)
[pmahend1@mba-i2 ~]$ hadoop jar /users/pmahend1/Jars/RandomForest-0.0.1-SNAPSHOT.jar rfalgorithm.RandomForest Car/car.c45-names.attributes.txt Car/car.data.txt
==========Random Forest Algorithm==========
Available Attributes: [buying, maint, doors, persons, lug_boot, safety, label]
1. Enter the Stable Attribute(s):
buying,maint,doors,persons
Stable Attribute(s): [buying, maint, doors, persons]
Available Attribute(s): [lug_boot, safety, label]
1. Enter the Decision Attribute:
safety

Available Decision Attributes: [safetyhigh, safetylow, safetymed]
Enter the Decision From Attribute:
safetylow
Enter the Decision To Attribute:
safetyhigh
Stable Attribute(s): [buying, maint, doors, persons]
Decision Attribute: [safety]
Decision From Attribute: safetylow
Decision To Attribute: safetyhigh
Flexible Attribute(s): [lug_boot, label]
Enter the minimum Support:
1
Enter the minimum Confidence %:
80
Exception in thread "main" java.lang.ArrayIndexOutOfBoundsException: 2
        at rfalgorithm.RandomForest.main(RandomForest.java:187)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.apache.hadoop.util.RunJar.run(RunJar.java:221)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:136)
[pmahend1@mba-i2 ~]$ hadoop jar /users/pmahend1/Jars/RandomForest-0.0.1-SNAPSHOT.jar rfalgorithm.RandomForest Car/car.c45-names.attributes.txt Car/car.data.txt
==========Random Forest Algorithm==========
Available Attributes: [buying, maint, doors, persons, lug_boot, safety, label]
1. Enter the Stable Attribute(s):
label
Stable Attribute(s): [label]
Available Attribute(s): [buying, maint, doors, persons, lug_boot, safety]
1. Enter the Decision Attribute:
buying

Available Decision Attributes: [buyinghigh, buyinglow, buyingvhigh, buyingmed]
Enter the Decision From Attribute:
buyinglow
Enter the Decision To Attribute:
buyinghigh
Stable Attribute(s): [label]
Decision Attribute: [buying]
Decision From Attribute: buyinglow
Decision To Attribute: buyinghigh
Flexible Attribute(s): [maint, doors, persons, lug_boot, safety]
Enter the minimum Support:
1
Enter the minimum Confidence %:
50
Exception in thread "main" java.lang.ArrayIndexOutOfBoundsException: 2
        at rfalgorithm.RandomForest.main(RandomForest.java:187)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.apache.hadoop.util.RunJar.run(RunJar.java:221)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:136)
[pmahend1@mba-i2 ~]$ hadoop jar /users/pmahend1/Jars/RandomForest-0.0.1-SNAPSHOT.jar rfalgorithm.RandomForest Car/car.c45-names.attributes.txt Car/car.data.txt CarOutputActionRules CarOutputAssoRules
==========Random Forest Algorithm==========
Available Attributes: [buying, maint, doors, persons, lug_boot, safety, label]
1. Enter the Stable Attribute(s):
buying,maint,doors,persons
Stable Attribute(s): [buying, maint, doors, persons]
Available Attribute(s): [lug_boot, safety, label]
1. Enter the Decision Attribute:
safety

Available Decision Attributes: [safetyhigh, safetylow, safetymed]
Enter the Decision From Attribute:
safetylow
Enter the Decision To Attribute:
safetyhigh
Stable Attribute(s): [buying, maint, doors, persons]
Decision Attribute: [safety]
Decision From Attribute: safetylow
Decision To Attribute: safetyhigh
Flexible Attribute(s): [lug_boot, label]
Enter the minimum Support:
1
Enter the minimum Confidence %:
80
16/11/06 18:25:49 INFO hdfs.DFSClient: Created token for pmahend1: HDFS_DELEGATION_TOKEN owner=pmahend1@ITS.UNCC.EDU, renewer=yarn, realUser=, issueDate=1478474749754, maxDate=1479079549754, sequenceNumber=9157, masterKeyId=157 on ha-hdfs:dsba
16/11/06 18:25:49 INFO security.TokenCache: Got dt for hdfs://dsba; Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:dsba, Ident: (token for pmahend1: HDFS_DELEGATION_TOKEN owner=pmahend1@ITS.UNCC.EDU, renewer=yarn, realUser=, issueDate=1478474749754, maxDate=1479079549754, sequenceNumber=9157, masterKeyId=157)
16/11/06 18:25:49 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
16/11/06 18:25:50 INFO input.FileInputFormat: Total input paths to process : 1
16/11/06 18:25:50 INFO mapreduce.JobSubmitter: number of splits:5
16/11/06 18:25:50 INFO Configuration.deprecation: mapred.max.split.size is deprecated. Instead, use mapreduce.input.fileinputformat.split.maxsize
16/11/06 18:25:50 INFO Configuration.deprecation: mapred.min.split.size is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize
16/11/06 18:25:50 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1470409205513_8252
16/11/06 18:25:50 INFO mapreduce.JobSubmitter: Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:dsba, Ident: (token for pmahend1: HDFS_DELEGATION_TOKEN owner=pmahend1@ITS.UNCC.EDU, renewer=yarn, realUser=, issueDate=1478474749754, maxDate=1479079549754, sequenceNumber=9157, masterKeyId=157)
16/11/06 18:25:50 INFO impl.YarnClientImpl: Submitted application application_1470409205513_8252
16/11/06 18:25:50 INFO mapreduce.Job: The url to track the job: http://mba-hm1.uncc.edu:8088/proxy/application_1470409205513_8252/
16/11/06 18:25:50 INFO mapreduce.Job: Running job: job_1470409205513_8252
16/11/06 18:28:14 INFO mapreduce.Job: Job job_1470409205513_8252 running in uber mode : false
16/11/06 18:28:14 INFO mapreduce.Job:  map 0% reduce 0%
16/11/06 18:28:26 INFO mapreduce.Job:  map 67% reduce 0%
16/11/06 18:28:37 INFO mapreduce.Job:  map 73% reduce 0%
16/11/06 18:28:40 INFO mapreduce.Job:  map 80% reduce 0%
16/11/06 18:28:50 INFO mapreduce.Job:  map 87% reduce 0%
16/11/06 18:28:54 INFO mapreduce.Job:  map 93% reduce 0%
16/11/06 18:29:03 INFO mapreduce.Job:  map 100% reduce 0%
16/11/06 18:29:05 INFO mapreduce.Job:  map 100% reduce 100%
16/11/06 18:29:05 INFO mapreduce.Job: Job job_1470409205513_8252 completed successfully
16/11/06 18:29:05 INFO mapreduce.Job: Counters: 49
        File System Counters
                FILE: Number of bytes read=14249
                FILE: Number of bytes written=786663
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
                HDFS: Number of bytes read=156140
                HDFS: Number of bytes written=28193
                HDFS: Number of read operations=18
                HDFS: Number of large read operations=0
                HDFS: Number of write operations=2
        Job Counters
                Launched map tasks=5
                Launched reduce tasks=1
                Data-local map tasks=5
                Total time spent by all maps in occupied slots (ms)=328986
                Total time spent by all reduces in occupied slots (ms)=15362
                Total time spent by all map tasks (ms)=164493
                Total time spent by all reduce tasks (ms)=7681
                Total vcore-seconds taken by all map tasks=164493
                Total vcore-seconds taken by all reduce tasks=7681
                Total megabyte-seconds taken by all map tasks=336881664
                Total megabyte-seconds taken by all reduce tasks=15730688
        Map-Reduce Framework
                Map input records=1728
                Map output records=787
                Map output bytes=164839
                Map output materialized bytes=15368
                Input split bytes=535
                Combine input records=0
                Combine output records=0
                Reduce input groups=659
                Reduce shuffle bytes=15368
                Reduce input records=787
                Reduce output records=124
                Spilled Records=1574
                Shuffled Maps =5
                Failed Shuffles=0
                Merged Map outputs=5
                GC time elapsed (ms)=1112
                CPU time spent (ms)=158310
                Physical memory (bytes) snapshot=5095182336
                Virtual memory (bytes) snapshot=23534280704
                Total committed heap usage (bytes)=5727322112
        Shuffle Errors
                BAD_ID=0
                CONNECTION=0
                IO_ERROR=0
                WRONG_LENGTH=0
                WRONG_MAP=0
                WRONG_REDUCE=0
        File Input Format Counters
                Bytes Read=155605
        File Output Format Counters
                Bytes Written=28193
16/11/06 18:29:05 INFO hdfs.DFSClient: Created token for pmahend1: HDFS_DELEGATION_TOKEN owner=pmahend1@ITS.UNCC.EDU, renewer=yarn, realUser=, issueDate=1478474945785, maxDate=1479079745785, sequenceNumber=9166, masterKeyId=157 on ha-hdfs:dsba
16/11/06 18:29:05 INFO security.TokenCache: Got dt for hdfs://dsba; Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:dsba, Ident: (token for pmahend1: HDFS_DELEGATION_TOKEN owner=pmahend1@ITS.UNCC.EDU, renewer=yarn, realUser=, issueDate=1478474945785, maxDate=1479079745785, sequenceNumber=9166, masterKeyId=157)
16/11/06 18:29:05 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
16/11/06 18:29:05 INFO input.FileInputFormat: Total input paths to process : 1
16/11/06 18:29:05 INFO mapreduce.JobSubmitter: number of splits:5
16/11/06 18:29:05 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1470409205513_8261
16/11/06 18:29:05 INFO mapreduce.JobSubmitter: Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:dsba, Ident: (token for pmahend1: HDFS_DELEGATION_TOKEN owner=pmahend1@ITS.UNCC.EDU, renewer=yarn, realUser=, issueDate=1478474945785, maxDate=1479079745785, sequenceNumber=9166, masterKeyId=157)
16/11/06 18:29:06 INFO impl.YarnClientImpl: Submitted application application_1470409205513_8261
16/11/06 18:29:06 INFO mapreduce.Job: The url to track the job: http://mba-hm1.uncc.edu:8088/proxy/application_1470409205513_8261/
16/11/06 18:29:06 INFO mapreduce.Job: Running job: job_1470409205513_8261
16/11/06 18:31:45 INFO mapreduce.Job: Job job_1470409205513_8261 running in uber mode : false
16/11/06 18:31:45 INFO mapreduce.Job:  map 0% reduce 0%
16/11/06 18:31:58 INFO mapreduce.Job:  map 20% reduce 0%
16/11/06 18:31:59 INFO mapreduce.Job:  map 73% reduce 0%
16/11/06 18:32:00 INFO mapreduce.Job:  map 80% reduce 0%
16/11/06 18:32:01 INFO mapreduce.Job:  map 87% reduce 0%
16/11/06 18:32:04 INFO mapreduce.Job:  map 93% reduce 0%
16/11/06 18:32:05 INFO mapreduce.Job:  map 100% reduce 0%
16/11/06 18:32:11 INFO mapreduce.Job:  map 100% reduce 100%
16/11/06 18:32:11 INFO mapreduce.Job: Job job_1470409205513_8261 completed successfully
16/11/06 18:32:11 INFO mapreduce.Job: Counters: 49
        File System Counters
                FILE: Number of bytes read=31643
                FILE: Number of bytes written=822862
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
                HDFS: Number of bytes read=156140
                HDFS: Number of bytes written=60078
                HDFS: Number of read operations=18
                HDFS: Number of large read operations=0
                HDFS: Number of write operations=2
        Job Counters
                Launched map tasks=5
                Launched reduce tasks=1
                Data-local map tasks=5
                Total time spent by all maps in occupied slots (ms)=151894
                Total time spent by all reduces in occupied slots (ms)=9234
                Total time spent by all map tasks (ms)=75947
                Total time spent by all reduce tasks (ms)=4617
                Total vcore-seconds taken by all map tasks=75947
                Total vcore-seconds taken by all reduce tasks=4617
                Total megabyte-seconds taken by all map tasks=155539456
                Total megabyte-seconds taken by all reduce tasks=9455616
        Map-Reduce Framework
                Map input records=1728
                Map output records=1486
                Map output bytes=321758
                Map output materialized bytes=34055
                Input split bytes=535
                Combine input records=0
                Combine output records=0
                Reduce input groups=1215
                Reduce shuffle bytes=34055
                Reduce input records=1486
                Reduce output records=268
                Spilled Records=2972
                Shuffled Maps =5
                Failed Shuffles=0
                Merged Map outputs=5
                GC time elapsed (ms)=815
                CPU time spent (ms)=75370
                Physical memory (bytes) snapshot=4942368768
                Virtual memory (bytes) snapshot=23563046912
                Total committed heap usage (bytes)=5697961984
        Shuffle Errors
                BAD_ID=0
                CONNECTION=0
                IO_ERROR=0
                WRONG_LENGTH=0
                WRONG_MAP=0
                WRONG_REDUCE=0
        File Input Format Counters
                Bytes Read=155605
        File Output Format Counters
                Bytes Written=60078
[pmahend1@mba-i2 ~]$                 HDFS: Number of bytes written=60078
                HDFS: Number of read operations=18
                HDFS: Number of large read operations=0
                HDFS: Number of write operations=2
        Job Counters
                Launched map tasks=5
                Launched reduce tasks=1
                Data-local map tasks=5
                Total time spent by all maps in occupied slots (ms)=151894
                Total time spent by all reduces in occupied slots (ms)=9234
                Total time spent by all map tasks (ms)=75947
                Total time spent by all reduce tasks (ms)=4617
                Total vcore-seconds taken by all map tasks=75947
-bash: HDFS:: command not found
[pmahend1@mba-i2 ~]$                 HDFS: Number of read operations=18
-bash: HDFS:: command not found
                Total vcore-seconds taken by all reduce tasks=4617
                Total megabyte-seconds taken by all map tasks=155539456
                Total megabyte-seconds taken by all reduce tasks=9455616
        Map-Reduce Framework
                Map input records=1728
                Map output records=1486
             [pmahend1@mba-i2 ~]$                 HDFS: Number of large read operations=0
-bash: HDFS:: command not found
[pmahend1@mba-i2 ~]$                 HDFS: Number of write operations=2
-bash: HDFS:: command not found
[pmahend1@mba-i2 ~]$         Job Counters
-bash: Job: command not found
[pmahend1@mba-i2 ~]$                 Launched map tasks=5
-bash: Launched: command not found
[pmahend1@mba-i2 ~]$                 Launched reduce tasks=1
-bash: Launched: command not found
[pmahend1@mba-i2 ~]$                 Data-local map tasks=5
-bash: Data-local: command not found
[pmahend1@mba-i2 ~]$                 Total time spent by all maps in occupied slots (ms)=151894
-bash: syntax error near unexpected token `('
[pmahend1@mba-i2 ~]$                 Total time spent by all reduces in occupied slots (ms)=9234
-bash: syntax error near unexpected token `('
[pmahend1@mba-i2 ~]$                 Total time spent by all map tasks (ms)=75947
-bash: syntax error near unexpected token `('
[pmahend1@mba-i2 ~]$                 Total time spent by all reduce tasks (ms)=4617
-bash: syntax error near unexpected token `('
[pmahend1@mba-i2 ~]$                 Total vcore-seconds taken by all map tasks=75947
-bash: Total: command not found
[pmahend1@mba-i2 ~]$                 Total vcore-seconds taken by all reduce tasks=4617
-bash: Total: command not found
[pmahend1@mba-i2 ~]$                 Total megabyte-seconds taken by all map tasks=155539456
-bash: Total: command not found
[pmahend1@mba-i2 ~]$                 Total megabyte-seconds taken by all reduce tasks=9455616
-bash: Total: command not found
[pmahend1@mba-i2 ~]$         Map-Reduce Framework
-bash: Map-Reduce: command not found
[pmahend1@mba-i2 ~]$                 Map input records=1728
-bash: Map: command not found
[pmahend1@mba-i2 ~]$                 Map output records=1486
-bash: Map: command not found
[pmahend1@mba-i2 ~]$                 Map output bytes=321758
-bash: Map: command not found
[pmahend1@mba-i2 ~]$                 Map output materialized bytes=34055
-bash: Map: command not found
[pmahend1@mba-i2 ~]$                 Input split bytes=535
-bash: Input: command not found
[pmahend1@mba-i2 ~]$                 Combine input records=0
-bash: Combine: command not found
[pmahend1@mba-i2 ~]$                 Combine output records=0
-bash: Combine: command not found
[pmahend1@mba-i2 ~]$                 Reduce input groups=1215
-bash: Reduce: command not found
[pmahend1@mba-i2 ~]$                 Reduce shuffle bytes=34055
-bash: Reduce: command not found
[pmahend1@mba-i2 ~]$                 Reduce input records=1486
-bash: Reduce: command not found
                Reduce output records=268
                Spilled Records=2972
                Shuffled Maps =5
                Failed Shuffles=0
                Merged Map outputs=5
                GC time elapsed (ms)=815
                CPU time spent (ms)=75370
                Physical memory (bytes) snapshot=4942368768
                Virtual memory (bytes) snapshot=23563046912
                Tota[pmahend1@mba-i2 ~]$                 Reduce output records=268
-bash: Reduce: command not found
[pmahend1@mba-i2 ~]$                 Spilled Records=2972
-bash: Spilled: command not found
[pmahend1@mba-i2 ~]$                 Shuffled Maps =5
-bash: Shuffled: command not found
[pmahend1@mba-i2 ~]$                 Failed Shuffles=0
-bash: Failed: command not found
[pmahend1@mba-i2 ~]$                 Merged Map outputs=5
-bash: Merged: command not found
[pmahend1@mba-i2 ~]$                 GC time elapsed (ms)=815
-bash: syntax error near unexpected token `('
[pmahend1@mba-i2 ~]$                 CPU time spent (ms)=75370
-bash: syntax error near unexpected token `('
[pmahend1@mba-i2 ~]$                 Physical memory (bytes) snapshot=4942368768
-bash: syntax error near unexpected token `('
[pmahend1@mba-i2 ~]$                 Virtual memory (bytes) snapshot=23563046912
-bash: syntax error near unexpected token `('
[pmahend1@mba-i2 ~]$                 Total committed heap usage (bytes)=5697961984
-bash: syntax error near unexpected token `('
[pmahend1@mba-i2 ~]$         Shuffle Errors
-bash: Shuffle: command not found
[pmahend1@mba-i2 ~]$                 BAD_ID=0
[pmahend1@mba-i2 ~]$                 CONNECTION=0
[pmahend1@mba-i2 ~]$                 IO_ERROR=0
[pmahend1@mba-i2 ~]$                 WRONG_LENGTH=0
[pmahend1@mba-i2 ~]$                 WRONG_MAP=0
[pmahend1@mba-i2 ~]$                 WRONG_REDUCE=0
[pmahend1@mba-i2 ~]$         File Input Format Counters
-bash: File: command not found
[pmahend1@mba-i2 ~]$                 Bytes Read=155605
-bash: Bytes: command not found
[pmahend1@mba-i2 ~]$         File Output Format Counters
-bash: File: command not found
[pmahend1@mba-i2 ~]$                 Bytes Written=60078
-bash: Bytes: command not found
[pmahend1@mba-i2 ~]$ [pmahend1@mba-i2 ~]$
-bash: [pmahend1@mba-i2: command not found
[pmahend1@mba-i2 ~]$ hadoop jar /users/pmahend1/Jars/RandomForest-0.0.1-SNAPSHOT.jar rfalgorithm.RandomForest Mammpgraphic/mammographic_attribute.txt Mammpgraphic/mammographic_masses.data.txt Mammographic/ActionRulesOutput Mammographic/AssociationActionRulesOutput
Exception in thread "main" java.io.FileNotFoundException: Mammpgraphic/mammographic_attribute.txt (No such file or directory)
        at java.io.FileInputStream.open0(Native Method)
        at java.io.FileInputStream.open(FileInputStream.java:195)
        at java.io.FileInputStream.<init>(FileInputStream.java:138)
        at java.io.FileReader.<init>(FileReader.java:72)
        at rfalgorithm.RandomForest.main(RandomForest.java:125)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.apache.hadoop.util.RunJar.run(RunJar.java:221)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:136)
[pmahend1@mba-i2 ~]$ hadoop fs -put /users/pmahend1/Mammographic
put: `/users/pmahend1/Mammographic': No such file or directory
[pmahend1@mba-i2 ~]$ hadoop fs -put /users/pmahend1/Mammographic
put: `/users/pmahend1/Mammographic': No such file or directory
[pmahend1@mba-i2 ~]$ hadoop fs -put users/pmahend1/Mammographic
put: `users/pmahend1/Mammographic': No such file or directory
[pmahend1@mba-i2 ~]$ hadoop fs -put /users/pmahend1/Mammographic
put: `/users/pmahend1/Mammographic': No such file or directory
[pmahend1@mba-i2 ~]$ hadoop fs -put /users/pmahend1/Mammographic
put: `/users/pmahend1/Mammographic': No such file or directory
[pmahend1@mba-i2 ~]$ ls /users/pmahend1/Mammographic
ls: cannot access /users/pmahend1/Mammographic: No such file or directory
[pmahend1@mba-i2 ~]$ ls -ltr
total 0
drwxrwsr-x 2 pmahend1 pmahend1  10 Nov  2 20:45 perl5
drwxrwsr-x 2 pmahend1 pmahend1  79 Nov  6 01:27 Cancer
drwxrwsr-x 2 pmahend1 pmahend1 119 Nov  6 18:13 Jars
drwxrwsr-x 2 pmahend1 pmahend1  72 Nov  6 18:17 Car
[pmahend1@mba-i2 ~]$ hadoop fs -put /users/pmahend1/Mammographic
[pmahend1@mba-i2 ~]$ hadoop jar /users/pmahend1/Jars/RandomForest-0.0.1-SNAPSHOT.jar rfalgorithm.RandomForest Mammpgraphic/mammographic_attribute.txt Mammpgraphic/mammographic_masses.data.txt Mammographic/ActionRulesOutput Mammographic/AssociationActionRulesOutput
Exception in thread "main" java.io.FileNotFoundException: Mammpgraphic/mammographic_attribute.txt (No such file or directory)
        at java.io.FileInputStream.open0(Native Method)
        at java.io.FileInputStream.open(FileInputStream.java:195)
        at java.io.FileInputStream.<init>(FileInputStream.java:138)
        at java.io.FileReader.<init>(FileReader.java:72)
        at rfalgorithm.RandomForest.main(RandomForest.java:125)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.apache.hadoop.util.RunJar.run(RunJar.java:221)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:136)
[pmahend1@mba-i2 ~]$ hadoop fs -ls
Found 7 items
drwx------   - pmahend1 pmahend1          0 2016-11-06 01:47 .Trash
drwx------   - pmahend1 pmahend1          0 2016-11-06 18:32 .staging
drwxr-xr-x   - pmahend1 pmahend1          0 2016-11-06 12:46 Cancer
drwxr-xr-x   - pmahend1 pmahend1          0 2016-11-06 18:19 Car
drwxr-xr-x   - pmahend1 pmahend1          0 2016-11-06 18:29 CarOutputActionRules
drwxr-xr-x   - pmahend1 pmahend1          0 2016-11-06 18:32 CarOutputAssoRules
drwxr-xr-x   - pmahend1 pmahend1          0 2016-11-06 18:46 Mammographic
[pmahend1@mba-i2 ~]$ hadoop fs -ls Mammographic
Found 2 items
-rw-r--r--   3 pmahend1 pmahend1         40 2016-11-06 18:46 Mammographic/mammographic_attribute.txt
-rw-r--r--   3 pmahend1 pmahend1       6999 2016-11-06 18:46 Mammographic/mammographic_masses.data.txt
[pmahend1@mba-i2 ~]$ hadoop jar /users/pmahend1/Jars/RandomForest-0.0.1-SNAPSHOT.jar rfalgorithm.RandomForest Mammpgraphic/mammographic_attribute.txt Mammpgraphic/mammographic_masses.data.txt Mammographic/ActionRulesOutput Mammographic/AssociationActionRulesOutput
Exception in thread "main" java.io.FileNotFoundException: Mammpgraphic/mammographic_attribute.txt (No such file or directory)
        at java.io.FileInputStream.open0(Native Method)
        at java.io.FileInputStream.open(FileInputStream.java:195)
        at java.io.FileInputStream.<init>(FileInputStream.java:138)
        at java.io.FileReader.<init>(FileReader.java:72)
        at rfalgorithm.RandomForest.main(RandomForest.java:125)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.apache.hadoop.util.RunJar.run(RunJar.java:221)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:136)
[pmahend1@mba-i2 ~]$ hadoop jar /users/pmahend1/Jars/RandomForest-0.0.1-SNAPSHOT.jar rfalgorithm.RandomForest Mammpgraphic/mammographic_attribute.txt Mammographic/mammographic_masses.data.txt Mammographic/ActionRulesOutput Mammographic/AssociationActionRulesOutput
Exception in thread "main" java.io.FileNotFoundException: Mammpgraphic/mammographic_attribute.txt (No such file or directory)
        at java.io.FileInputStream.open0(Native Method)
        at java.io.FileInputStream.open(FileInputStream.java:195)
        at java.io.FileInputStream.<init>(FileInputStream.java:138)
        at java.io.FileReader.<init>(FileReader.java:72)
        at rfalgorithm.RandomForest.main(RandomForest.java:125)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.apache.hadoop.util.RunJar.run(RunJar.java:221)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:136)
[pmahend1@mba-i2 ~]$ hadoop jar /users/pmahend1/Jars/RandomForest-0.0.1-SNAPSHOT.jar rfalgorithm.RandomForest Mammographic/mammographic_attribute.txt Mammographic/mammographic_masses.data.txt Mammographic/ActionRulesOutput Mammographic/AssociationActionRulesOutput
==========Random Forest Algorithm==========
Available Attributes: [birads, age, shape, margin, density, severity]
1. Enter the Stable Attribute(s):
margin
Stable Attribute(s): [margin]
Available Attribute(s): [birads, age, shape, density, severity]
1. Enter the Decision Attribute:
severity

Available Decision Attributes: [severity0, severity1]
Enter the Decision From Attribute:
severity0
Enter the Decision To Attribute:
severity1
Stable Attribute(s): [margin]
Decision Attribute: [severity]
Decision From Attribute: severity0
Decision To Attribute: severity1
Flexible Attribute(s): [birads, age, shape, density]
Enter the minimum Support:
1
Enter the minimum Confidence %:
70
16/11/06 18:49:34 INFO hdfs.DFSClient: Created token for pmahend1: HDFS_DELEGATION_TOKEN owner=pmahend1@ITS.UNCC.EDU, renewer=yarn, realUser=, issueDate=1478476174557, maxDate=1479080974557, sequenceNumber=9223, masterKeyId=157 on ha-hdfs:dsba
16/11/06 18:49:34 INFO security.TokenCache: Got dt for hdfs://dsba; Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:dsba, Ident: (token for pmahend1: HDFS_DELEGATION_TOKEN owner=pmahend1@ITS.UNCC.EDU, renewer=yarn, realUser=, issueDate=1478476174557, maxDate=1479080974557, sequenceNumber=9223, masterKeyId=157)
16/11/06 18:49:34 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
16/11/06 18:49:34 INFO input.FileInputFormat: Total input paths to process : 1
16/11/06 18:49:35 INFO mapreduce.JobSubmitter: number of splits:5
16/11/06 18:49:35 INFO Configuration.deprecation: mapred.max.split.size is deprecated. Instead, use mapreduce.input.fileinputformat.split.maxsize
16/11/06 18:49:35 INFO Configuration.deprecation: mapred.min.split.size is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize
16/11/06 18:49:35 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1470409205513_8317
16/11/06 18:49:35 INFO mapreduce.JobSubmitter: Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:dsba, Ident: (token for pmahend1: HDFS_DELEGATION_TOKEN owner=pmahend1@ITS.UNCC.EDU, renewer=yarn, realUser=, issueDate=1478476174557, maxDate=1479080974557, sequenceNumber=9223, masterKeyId=157)
16/11/06 18:49:35 INFO impl.YarnClientImpl: Submitted application application_1470409205513_8317
16/11/06 18:49:35 INFO mapreduce.Job: The url to track the job: http://mba-hm1.uncc.edu:8088/proxy/application_1470409205513_8317/
16/11/06 18:49:35 INFO mapreduce.Job: Running job: job_1470409205513_8317
16/11/06 18:49:42 INFO mapreduce.Job: Job job_1470409205513_8317 running in uber mode : false
16/11/06 18:49:42 INFO mapreduce.Job:  map 0% reduce 0%
16/11/06 18:49:57 INFO mapreduce.Job:  map 33% reduce 0%
16/11/06 18:49:58 INFO mapreduce.Job:  map 73% reduce 0%
16/11/06 18:50:04 INFO mapreduce.Job:  map 80% reduce 0%
16/11/06 18:50:05 INFO mapreduce.Job:  map 87% reduce 0%
16/11/06 18:50:09 INFO mapreduce.Job:  map 93% reduce 0%
16/11/06 18:50:11 INFO mapreduce.Job:  map 100% reduce 0%
16/11/06 18:50:16 INFO mapreduce.Job:  map 100% reduce 100%
16/11/06 18:50:16 INFO mapreduce.Job: Job job_1470409205513_8317 completed successfully
16/11/06 18:50:16 INFO mapreduce.Job: Counters: 49
        File System Counters
                FILE: Number of bytes read=413569
                FILE: Number of bytes written=1581972
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
                HDFS: Number of bytes read=21665
                HDFS: Number of bytes written=134349
                HDFS: Number of read operations=18
                HDFS: Number of large read operations=0
                HDFS: Number of write operations=2
        Job Counters
                Launched map tasks=5
                Launched reduce tasks=1
                Data-local map tasks=5
                Total time spent by all maps in occupied slots (ms)=204622
                Total time spent by all reduces in occupied slots (ms)=8530
                Total time spent by all map tasks (ms)=102311
                Total time spent by all reduce tasks (ms)=4265
                Total vcore-seconds taken by all map tasks=102311
                Total vcore-seconds taken by all reduce tasks=4265
                Total megabyte-seconds taken by all map tasks=209532928
                Total megabyte-seconds taken by all reduce tasks=8734720
        Map-Reduce Framework
                Map input records=500
                Map output records=32889
                Map output bytes=4030428
                Map output materialized bytes=411321
                Input split bytes=660
                Combine input records=0
                Combine output records=0
                Reduce input groups=31787
                Reduce shuffle bytes=411321
                Reduce input records=32889
                Reduce output records=1018
                Spilled Records=65778
                Shuffled Maps =5
                Failed Shuffles=0
                Merged Map outputs=5
                GC time elapsed (ms)=1465
                CPU time spent (ms)=112040
                Physical memory (bytes) snapshot=5366276096
                Virtual memory (bytes) snapshot=23570169856
                Total committed heap usage (bytes)=5885657088
        Shuffle Errors
                BAD_ID=0
                CONNECTION=0
                IO_ERROR=0
                WRONG_LENGTH=0
                WRONG_MAP=0
                WRONG_REDUCE=0
        File Input Format Counters
                Bytes Read=21005
        File Output Format Counters
                Bytes Written=134349
16/11/06 18:50:16 INFO hdfs.DFSClient: Created token for pmahend1: HDFS_DELEGATION_TOKEN owner=pmahend1@ITS.UNCC.EDU, renewer=yarn, realUser=, issueDate=1478476216388, maxDate=1479081016388, sequenceNumber=9227, masterKeyId=157 on ha-hdfs:dsba
16/11/06 18:50:16 INFO security.TokenCache: Got dt for hdfs://dsba; Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:dsba, Ident: (token for pmahend1: HDFS_DELEGATION_TOKEN owner=pmahend1@ITS.UNCC.EDU, renewer=yarn, realUser=, issueDate=1478476216388, maxDate=1479081016388, sequenceNumber=9227, masterKeyId=157)
16/11/06 18:50:16 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
16/11/06 18:50:16 INFO input.FileInputFormat: Total input paths to process : 1
16/11/06 18:50:16 INFO mapreduce.JobSubmitter: number of splits:5
16/11/06 18:50:16 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1470409205513_8321
16/11/06 18:50:16 INFO mapreduce.JobSubmitter: Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:dsba, Ident: (token for pmahend1: HDFS_DELEGATION_TOKEN owner=pmahend1@ITS.UNCC.EDU, renewer=yarn, realUser=, issueDate=1478476216388, maxDate=1479081016388, sequenceNumber=9227, masterKeyId=157)
16/11/06 18:50:17 INFO impl.YarnClientImpl: Submitted application application_1470409205513_8321
16/11/06 18:50:17 INFO mapreduce.Job: The url to track the job: http://mba-hm1.uncc.edu:8088/proxy/application_1470409205513_8321/
16/11/06 18:50:17 INFO mapreduce.Job: Running job: job_1470409205513_8321
hadoop jar /users/pmahend1/Jars/RandomForest-0.0.1-SNAPSHOT.jar rfalgorithm.RandomForest Mammographic/mammographic_attribute.txt Mammographic/mammographic_masses.data.txt Mammographic/ActionRulesOutput Mammographic/AssociationActionRulesOutput16/11/06 18:50:29 INFO mapreduce.Job: Job job_1470409205513_8321 running in uber mode : false
16/11/06 18:50:29 INFO mapreduce.Job:  map 0% reduce 0%
16/11/06 18:50:41 INFO mapreduce.Job






